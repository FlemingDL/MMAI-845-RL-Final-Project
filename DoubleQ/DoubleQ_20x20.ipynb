{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DoubleQ_20x20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEXIVM65oapM",
        "colab_type": "code",
        "outputId": "949ce890-e580-4927-bafe-5b1a06ee7450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv3MDxNv8dHn",
        "colab_type": "code",
        "outputId": "723caddd-968b-4a6c-b541-ecea9ca2611d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37R98CM3uNLI",
        "colab_type": "code",
        "outputId": "49ee69de-2de1-4052-daff-fec524907539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "!git clone https://github.com/FlemingDL/gym_fleming.git\n",
        "\n",
        "!pip install -e gym_fleming"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gym_fleming'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 99 (delta 37), reused 86 (delta 24), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n",
            "Obtaining file:///content/gym_fleming\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-fleming==0.0.2) (0.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gym-fleming==0.0.2) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym-fleming==0.0.2) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-fleming==0.0.2) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-fleming==0.0.2) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-fleming==0.0.2) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-fleming==0.0.2) (0.16.0)\n",
            "Installing collected packages: gym-fleming\n",
            "  Running setup.py develop for gym-fleming\n",
            "Successfully installed gym-fleming\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGWbBY4Aup1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from contextlib import closing\n",
        "from six import StringIO\n",
        "from gym import utils\n",
        "from gym.envs.toy_text import discrete\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import gym\n",
        "import gym_fleming\n",
        "from gym import wrappers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwzAIZwt9VhP",
        "colab_type": "code",
        "outputId": "d9cece6b-ddd6-4f25-bd83-29179fc21597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "# env = gym.make('taxi_fleming-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_5x5\",  video_callable=lambda episode_id: True, force=True)\n",
        "# env = gym.make('taxi_fleming-10x10-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_10x10\",  video_callable=lambda episode_id: True, force=True)\n",
        "# env = gym.make('taxi_fleming-15x15-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_15x15\",  video_callable=lambda episode_id: True, force=True)\n",
        "env = gym.make('taxi_fleming-20x20-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_20x20\",  video_callable=lambda episode_id: True, force=True)\n",
        "\n",
        "#  env = gym.wrappers.Monitor(env, directory, video_callable=lambda episode_id: episode_id%10==0)\n",
        "n_state = env.observation_space.n\n",
        "print(n_state)\n",
        "\n",
        "n_action = env.action_space.n\n",
        "print(n_action)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c888oFKpHpe0",
        "colab_type": "code",
        "outputId": "307dc41a-e1a1-45f4-8e07-d624d8d5897c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "env.render()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|R: | : : : : | : : : : | : : : : | : :G|\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| | : | : : | : | : : | : | : : |\u001b[43m \u001b[0m: | : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : | : : | : | : : | : | : : | : |\u001b[35mB\u001b[0m: |\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwYg-nUOJ3-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# class TaxiEnv(discrete.DiscreteEnv):\n",
        "#     \"\"\"\n",
        "#     The Taxi Problem\n",
        "#     from \"Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition\"\n",
        "#     by Tom Dietterich\n",
        "#     Description:\n",
        "#     There are four designated locations in the grid world indicated by R(ed), G(reen), Y(ellow), and B(lue). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drives to the passenger's location, picks up the passenger, drives to the passenger's destination (another one of the four specified locations), and then drops off the passenger. Once the passenger is dropped off, the episode ends.\n",
        "#     Observations: \n",
        "#     There are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is in the taxi), and 4 destination locations. \n",
        "    \n",
        "#     Passenger locations:\n",
        "#     - 0: R(ed)\n",
        "#     - 1: G(reen)\n",
        "#     - 2: Y(ellow)\n",
        "#     - 3: B(lue)\n",
        "#     - 4: in taxi\n",
        "    \n",
        "#     Destinations:\n",
        "#     - 0: R(ed)\n",
        "#     - 1: G(reen)\n",
        "#     - 2: Y(ellow)\n",
        "#     - 3: B(lue)\n",
        "        \n",
        "#     Actions:\n",
        "#     There are 6 discrete deterministic actions:\n",
        "#     - 0: move south\n",
        "#     - 1: move north\n",
        "#     - 2: move east \n",
        "#     - 3: move west \n",
        "#     - 4: pickup passenger\n",
        "#     - 5: dropoff passenger\n",
        "    \n",
        "#     Rewards: \n",
        "#     There is a reward of -1 for each action and an additional reward of +20 for delivering the passenger. There is a reward of -10 for executing actions \"pickup\" and \"dropoff\" illegally.\n",
        "    \n",
        "#     Rendering:\n",
        "#     - blue: passenger\n",
        "#     - magenta: destination\n",
        "#     - yellow: empty taxi\n",
        "#     - green: full taxi\n",
        "#     - other letters (R, G, Y and B): locations for passengers and destinations\n",
        "    \n",
        "#     state space is represented by:\n",
        "#         (taxi_row, taxi_col, passenger_location, destination)\n",
        "#     \"\"\"\n",
        "#     metadata = {'render.modes': ['human', 'ansi']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAvA0KEKdbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ">>> def double_q_learning(env, gamma, n_episode, alpha):\n",
        "...     \"\"\"\n",
        "...     Obtain the optimal policy with off-policy double \n",
        "        Q-learning method\n",
        "...     @param env: OpenAI Gym environment\n",
        "...     @param gamma: discount factor\n",
        "...     @param n_episode: number of episodes\n",
        "...     @return: the optimal Q-function, and the optimal policy\n",
        "...     \"\"\"\n",
        "...     n_action = env.action_space.n\n",
        "...     n_state = env.observation_space.n\n",
        "...     Q1 = torch.zeros(n_state, n_action)\n",
        "...     Q2 = torch.zeros(n_state, n_action)\n",
        "...     frames =[]\n",
        "...     for episode in range(n_episode):\n",
        "...         state = env.reset()\n",
        "...         is_done = False\n",
        "...         while not is_done:\n",
        "# ...             env.render()\n",
        "# ...             env.close()\n",
        "...             action = epsilon_greedy_policy(state, Q1 + Q2)\n",
        "...             next_state, reward, is_done, info = env.step(action)\n",
        "...             if (torch.rand(1).item() < 0.5):\n",
        "...                 best_next_action = torch.argmax(Q1[next_state])\n",
        "...                 td_delta = reward + gamma * Q2[next_state][best_next_action]  - Q1[state][action]\n",
        "...                 Q1[state][action] += alpha * td_delta\n",
        "...             else:\n",
        "...                 best_next_action = torch.argmax(Q2[next_state])\n",
        "...                 td_delta = reward + gamma * Q1[next_state][best_next_action] - Q2[state][action]\n",
        "...                 Q2[state][action] += alpha * td_delta\n",
        "...             length_episode[episode] += 1\n",
        "...             total_reward_episode[episode] += reward\n",
        "# ...             frames.append({'frame': env.render(mode='ansi'),'state': state,'action': action,'reward': reward})\n",
        "...             if is_done:\n",
        "...                 break\n",
        "...             state = next_state\n",
        "# ...     env.close()\n",
        "...     policy = {}\n",
        "...     Q = Q1 + Q2\n",
        "\n",
        "\n",
        "...     for state in range(n_state):\n",
        "...         policy[state] = torch.argmax(Q[state]).item()\n",
        "...     return Q, policy#,frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDirCtF8SwUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ">>> def gen_epsilon_greedy_policy(n_action, epsilon):\n",
        "        def policy_function(state, Q):\n",
        "            probs = torch.ones(n_action) * epsilon / n_action\n",
        "            best_action = torch.argmax(Q[state]).item()\n",
        "            probs[best_action] += 1.0 - epsilon\n",
        "            action = torch.multinomial(probs, 1).item()\n",
        "            return action\n",
        "        return policy_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMy0klpCPan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQfSMeJh399d",
        "colab_type": "text"
      },
      "source": [
        "Gamma = 1, Alpha = 0.4, Epsilon = 0.1\n",
        "\n",
        "\n",
        "141\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVvwFHENJft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ">>> n_episode = 2000\n",
        ">>> length_episode = [0] * n_episode\n",
        ">>> total_reward_episode = [0] * n_episode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXvqDJ8eFSXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha_options = [0.4, 0.5, 0.6]\n",
        "epsilon_options = [0.3, 0.1, 0.01]\n",
        "gamma = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LasQkAkKFSbN",
        "colab_type": "code",
        "outputId": "a41faa03-257f-4376-b886-84cc0987bc1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "for alpha in alpha_options:\n",
        "     for epsilon in epsilon_options:\n",
        "         length_episode = [0] * n_episode\n",
        "         total_reward_episode = [0] * n_episode\n",
        "         epsilon_greedy_policy = gen_epsilon_greedy_policy(env.action_space.n, epsilon)\n",
        "         double_q_learning(env, gamma, n_episode, alpha)\n",
        "         reward_per_step = [reward/float(step) for \n",
        "                            reward, step in zip(\n",
        "                        total_reward_episode, length_episode)]\n",
        "         print('alpha: {}, epsilon: {}'.format(alpha, epsilon))\n",
        "         print('Average reward over {} episodes: {}'.format(\n",
        "            n_episode, sum(total_reward_episode) / n_episode))\n",
        "         print('Average length over {} episodes: {}'.format(\n",
        "            n_episode, sum(length_episode) / n_episode))\n",
        "         print('Average reward per step over {} episodes: {}\\n'.format(\n",
        "            n_episode, sum(reward_per_step) / n_episode))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 0.4, epsilon: 0.3\n",
            "Average reward over 2000 episodes: -3644.3325\n",
            "Average length over 2000 episodes: 1596.939\n",
            "Average reward per step over 2000 episodes: -2.1561892832753258\n",
            "\n",
            "alpha: 0.4, epsilon: 0.1\n",
            "Average reward over 2000 episodes: -3268.065\n",
            "Average length over 2000 episodes: 1487.31\n",
            "Average reward per step over 2000 episodes: -2.058981527068195\n",
            "\n",
            "alpha: 0.4, epsilon: 0.01\n",
            "Average reward over 2000 episodes: -3157.6005\n",
            "Average length over 2000 episodes: 1450.2045\n",
            "Average reward per step over 2000 episodes: -2.023086241049618\n",
            "\n",
            "alpha: 0.5, epsilon: 0.3\n",
            "Average reward over 2000 episodes: -3335.5225\n",
            "Average length over 2000 episodes: 1401.8845\n",
            "Average reward per step over 2000 episodes: -2.2272988285111603\n",
            "\n",
            "alpha: 0.5, epsilon: 0.1\n",
            "Average reward over 2000 episodes: -3081.2705\n",
            "Average length over 2000 episodes: 1346.627\n",
            "Average reward per step over 2000 episodes: -2.102831994340026\n",
            "\n",
            "alpha: 0.5, epsilon: 0.01\n",
            "Average reward over 2000 episodes: -2973.443\n",
            "Average length over 2000 episodes: 1313.4455\n",
            "Average reward per step over 2000 episodes: -2.0450856631580323\n",
            "\n",
            "alpha: 0.6, epsilon: 0.3\n",
            "Average reward over 2000 episodes: -3165.209\n",
            "Average length over 2000 episodes: 1278.398\n",
            "Average reward per step over 2000 episodes: -2.2835741773235845\n",
            "\n",
            "alpha: 0.6, epsilon: 0.1\n",
            "Average reward over 2000 episodes: -2958.6025\n",
            "Average length over 2000 episodes: 1238.7055\n",
            "Average reward per step over 2000 episodes: -2.148824917092637\n",
            "\n",
            "alpha: 0.6, epsilon: 0.01\n",
            "Average reward over 2000 episodes: -3000.755\n",
            "Average length over 2000 episodes: 1268.6765\n",
            "Average reward per step over 2000 episodes: -2.1108950145225194\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoL9OgOFFSea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nki1lqfkFShX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i9diKndfSB5P",
        "colab": {}
      },
      "source": [
        "#10x10\n",
        ">>> gamma = 1\n",
        ">>> alpha = 0.4\n",
        ">>> epsilon = 0.01\n",
        ">>> epsilon_greedy_policy = gen_epsilon_greedy_policy(env.action_space.n, epsilon)\n",
        ">>> five_try = ['one','two','three','four','five']\n",
        "# >>> five_try = ['one']\n",
        ">>> for i in five_try:\n",
        ">>>   length_episode = [0] * n_episode\n",
        ">>>   total_reward_episode = [0] * n_episode\n",
        ">>>   optimal_Q, optimal_policy = double_q_learning(env, gamma, n_episode, alpha)\n",
        ">>>   vars()[\"length_episode_\"+i] = length_episode\n",
        ">>>   vars()[\"total_reward_episode_\"+i] = total_reward_episode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkKLkRi8FOty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "length_df = pd.DataFrame({'20x20_one' : length_episode_one ,\n",
        "                   '20x20_two' : length_episode_two,\n",
        "                   '20x20_three' : length_episode_three,\n",
        "                   '20x20_four' : length_episode_four,\n",
        "                   '20x20_five' : length_episode_five\n",
        "                   }\n",
        "                    )\n",
        "\n",
        "reward_df = pd.DataFrame({'20x20_one' : total_reward_episode_one ,\n",
        "                   '20x20_two' : total_reward_episode_two,\n",
        "                   '20x20_three' : total_reward_episode_three,\n",
        "                   '20x20_four' : total_reward_episode_four,\n",
        "                   '20x20_five' : total_reward_episode_five\n",
        "                   }\n",
        "                    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0k64buDFmhg",
        "colab_type": "code",
        "outputId": "dd9e5d3b-5e3c-4ad6-cf68-7eb6dec1333c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "length_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>20x20_one</th>\n",
              "      <th>20x20_two</th>\n",
              "      <th>20x20_three</th>\n",
              "      <th>20x20_four</th>\n",
              "      <th>20x20_five</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6440</td>\n",
              "      <td>3667</td>\n",
              "      <td>997</td>\n",
              "      <td>25508</td>\n",
              "      <td>13779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5425</td>\n",
              "      <td>4620</td>\n",
              "      <td>4916</td>\n",
              "      <td>16922</td>\n",
              "      <td>7782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11464</td>\n",
              "      <td>9534</td>\n",
              "      <td>3878</td>\n",
              "      <td>5873</td>\n",
              "      <td>1095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4884</td>\n",
              "      <td>4493</td>\n",
              "      <td>5958</td>\n",
              "      <td>4137</td>\n",
              "      <td>35037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5055</td>\n",
              "      <td>31396</td>\n",
              "      <td>20327</td>\n",
              "      <td>8500</td>\n",
              "      <td>2591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>53</td>\n",
              "      <td>678</td>\n",
              "      <td>80</td>\n",
              "      <td>426</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>439</td>\n",
              "      <td>1038</td>\n",
              "      <td>89</td>\n",
              "      <td>880</td>\n",
              "      <td>603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>90</td>\n",
              "      <td>160</td>\n",
              "      <td>69</td>\n",
              "      <td>93</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>190</td>\n",
              "      <td>749</td>\n",
              "      <td>405</td>\n",
              "      <td>409</td>\n",
              "      <td>438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>249</td>\n",
              "      <td>1523</td>\n",
              "      <td>1405</td>\n",
              "      <td>946</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      20x20_one  20x20_two  20x20_three  20x20_four  20x20_five\n",
              "0          6440       3667          997       25508       13779\n",
              "1          5425       4620         4916       16922        7782\n",
              "2         11464       9534         3878        5873        1095\n",
              "3          4884       4493         5958        4137       35037\n",
              "4          5055      31396        20327        8500        2591\n",
              "...         ...        ...          ...         ...         ...\n",
              "1995         53        678           80         426         600\n",
              "1996        439       1038           89         880         603\n",
              "1997         90        160           69          93          79\n",
              "1998        190        749          405         409         438\n",
              "1999        249       1523         1405         946          27\n",
              "\n",
              "[2000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxPkxR6IziV",
        "colab_type": "code",
        "outputId": "806910a2-834d-4f1c-fbc9-54df79894edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "reward_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>20x20_one</th>\n",
              "      <th>20x20_two</th>\n",
              "      <th>20x20_three</th>\n",
              "      <th>20x20_four</th>\n",
              "      <th>20x20_five</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-21161</td>\n",
              "      <td>-13312</td>\n",
              "      <td>-3946</td>\n",
              "      <td>-67085</td>\n",
              "      <td>-40173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-19741</td>\n",
              "      <td>-13491</td>\n",
              "      <td>-18755</td>\n",
              "      <td>-44792</td>\n",
              "      <td>-23727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-27427</td>\n",
              "      <td>-27054</td>\n",
              "      <td>-15620</td>\n",
              "      <td>-19091</td>\n",
              "      <td>-4242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-13575</td>\n",
              "      <td>-8792</td>\n",
              "      <td>-18006</td>\n",
              "      <td>-12333</td>\n",
              "      <td>-87576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-18930</td>\n",
              "      <td>-74863</td>\n",
              "      <td>-48773</td>\n",
              "      <td>-18559</td>\n",
              "      <td>-5522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>-50</td>\n",
              "      <td>-1323</td>\n",
              "      <td>-95</td>\n",
              "      <td>-891</td>\n",
              "      <td>-1335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>-1021</td>\n",
              "      <td>-2142</td>\n",
              "      <td>-149</td>\n",
              "      <td>-1885</td>\n",
              "      <td>-1320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>-96</td>\n",
              "      <td>-283</td>\n",
              "      <td>-75</td>\n",
              "      <td>-144</td>\n",
              "      <td>-130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>-304</td>\n",
              "      <td>-1628</td>\n",
              "      <td>-888</td>\n",
              "      <td>-910</td>\n",
              "      <td>-903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>-471</td>\n",
              "      <td>-3365</td>\n",
              "      <td>-3175</td>\n",
              "      <td>-2059</td>\n",
              "      <td>-6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      20x20_one  20x20_two  20x20_three  20x20_four  20x20_five\n",
              "0        -21161     -13312        -3946      -67085      -40173\n",
              "1        -19741     -13491       -18755      -44792      -23727\n",
              "2        -27427     -27054       -15620      -19091       -4242\n",
              "3        -13575      -8792       -18006      -12333      -87576\n",
              "4        -18930     -74863       -48773      -18559       -5522\n",
              "...         ...        ...          ...         ...         ...\n",
              "1995        -50      -1323          -95        -891       -1335\n",
              "1996      -1021      -2142         -149       -1885       -1320\n",
              "1997        -96       -283          -75        -144        -130\n",
              "1998       -304      -1628         -888        -910        -903\n",
              "1999       -471      -3365        -3175       -2059          -6\n",
              "\n",
              "[2000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9GxJWdJpSB5f",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "length_df.to_csv('20x20_0.4_0.01_length_result.csv') \n",
        "reward_df.to_csv('20x20_0.4_0.01_reward_result.csv') \n",
        "# files.download('filename.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJ--NEEFSk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNpMB2-iMN7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUXWmTwuMOHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbM6WnT9MOKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6rQ_K47MOPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmdGsIHXMOSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UsfEX-HMN_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4z4YrmoOJR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}