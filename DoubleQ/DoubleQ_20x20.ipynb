{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DoubleQ_20x20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEXIVM65oapM",
        "colab_type": "code",
        "outputId": "4725de5b-e18a-4ee7-ddc8-4db7eea6846d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv3MDxNv8dHn",
        "colab_type": "code",
        "outputId": "b0a9c926-565e-4c2d-ece4-6de1ae5d2fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37R98CM3uNLI",
        "colab_type": "code",
        "outputId": "3fa099f4-2426-489c-d170-94be792e08e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "!git clone https://github.com/FlemingDL/gym_fleming.git\n",
        "\n",
        "!pip install -e gym_fleming"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gym_fleming'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 99 (delta 37), reused 86 (delta 24), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n",
            "Obtaining file:///content/gym_fleming\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-fleming==0.0.2) (0.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gym-fleming==0.0.2) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym-fleming==0.0.2) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-fleming==0.0.2) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-fleming==0.0.2) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-fleming==0.0.2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-fleming==0.0.2) (0.16.0)\n",
            "Installing collected packages: gym-fleming\n",
            "  Running setup.py develop for gym-fleming\n",
            "Successfully installed gym-fleming\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGWbBY4Aup1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from contextlib import closing\n",
        "from six import StringIO\n",
        "from gym import utils\n",
        "from gym.envs.toy_text import discrete\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import gym\n",
        "import gym_fleming\n",
        "from gym import wrappers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwzAIZwt9VhP",
        "colab_type": "code",
        "outputId": "510f8f98-362d-4cf8-894f-6ac51ab0c837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "# env = gym.make('taxi_fleming-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_5x5\",  video_callable=lambda episode_id: True, force=True)\n",
        "# env = gym.make('taxi_fleming-10x10-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_10x10\",  video_callable=lambda episode_id: True, force=True)\n",
        "# env = gym.make('taxi_fleming-15x15-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_15x15\",  video_callable=lambda episode_id: True, force=True)\n",
        "env = gym.make('taxi_fleming-20x20-v0')\n",
        "# env = gym.wrappers.Monitor(env, \"./drive/My Drive/Colab Notebooks/RL Project/double_Q_20x20\",  video_callable=lambda episode_id: True, force=True)\n",
        "\n",
        "#  env = gym.wrappers.Monitor(env, directory, video_callable=lambda episode_id: episode_id%10==0)\n",
        "n_state = env.observation_space.n\n",
        "print(n_state)\n",
        "\n",
        "n_action = env.action_space.n\n",
        "print(n_action)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c888oFKpHpe0",
        "colab_type": "code",
        "outputId": "21ac96df-5950-4017-e92b-9f898ecf18e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "env.render()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------+\n",
            "|R: | : : : : | : : : : | : : : : | : :G|\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| : | : : : : | :\u001b[43m \u001b[0m: : : | : : : : | : : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : | : : : : | : : : : | : : : : | : : |\n",
            "| : : : : : : : : : : : : : : : : : : : |\n",
            "| | : | : : | : | : : | : | : : | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : | : : | : | : : | : | : : | : |\u001b[35mB\u001b[0m: |\n",
            "+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwYg-nUOJ3-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# class TaxiEnv(discrete.DiscreteEnv):\n",
        "#     \"\"\"\n",
        "#     The Taxi Problem\n",
        "#     from \"Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition\"\n",
        "#     by Tom Dietterich\n",
        "#     Description:\n",
        "#     There are four designated locations in the grid world indicated by R(ed), G(reen), Y(ellow), and B(lue). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drives to the passenger's location, picks up the passenger, drives to the passenger's destination (another one of the four specified locations), and then drops off the passenger. Once the passenger is dropped off, the episode ends.\n",
        "#     Observations: \n",
        "#     There are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is in the taxi), and 4 destination locations. \n",
        "    \n",
        "#     Passenger locations:\n",
        "#     - 0: R(ed)\n",
        "#     - 1: G(reen)\n",
        "#     - 2: Y(ellow)\n",
        "#     - 3: B(lue)\n",
        "#     - 4: in taxi\n",
        "    \n",
        "#     Destinations:\n",
        "#     - 0: R(ed)\n",
        "#     - 1: G(reen)\n",
        "#     - 2: Y(ellow)\n",
        "#     - 3: B(lue)\n",
        "        \n",
        "#     Actions:\n",
        "#     There are 6 discrete deterministic actions:\n",
        "#     - 0: move south\n",
        "#     - 1: move north\n",
        "#     - 2: move east \n",
        "#     - 3: move west \n",
        "#     - 4: pickup passenger\n",
        "#     - 5: dropoff passenger\n",
        "    \n",
        "#     Rewards: \n",
        "#     There is a reward of -1 for each action and an additional reward of +20 for delivering the passenger. There is a reward of -10 for executing actions \"pickup\" and \"dropoff\" illegally.\n",
        "    \n",
        "#     Rendering:\n",
        "#     - blue: passenger\n",
        "#     - magenta: destination\n",
        "#     - yellow: empty taxi\n",
        "#     - green: full taxi\n",
        "#     - other letters (R, G, Y and B): locations for passengers and destinations\n",
        "    \n",
        "#     state space is represented by:\n",
        "#         (taxi_row, taxi_col, passenger_location, destination)\n",
        "#     \"\"\"\n",
        "#     metadata = {'render.modes': ['human', 'ansi']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAvA0KEKdbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ">>> def double_q_learning(env, gamma, n_episode, alpha):\n",
        "...     \"\"\"\n",
        "...     Obtain the optimal policy with off-policy double \n",
        "        Q-learning method\n",
        "...     @param env: OpenAI Gym environment\n",
        "...     @param gamma: discount factor\n",
        "...     @param n_episode: number of episodes\n",
        "...     @return: the optimal Q-function, and the optimal policy\n",
        "...     \"\"\"\n",
        "...     n_action = env.action_space.n\n",
        "...     n_state = env.observation_space.n\n",
        "...     Q1 = torch.zeros(n_state, n_action)\n",
        "...     Q2 = torch.zeros(n_state, n_action)\n",
        "...     frames =[]\n",
        "...     for episode in range(n_episode):\n",
        "...         state = env.reset()\n",
        "...         is_done = False\n",
        "...         while not is_done:\n",
        "# ...             env.render()\n",
        "# ...             env.close()\n",
        "...             action = epsilon_greedy_policy(state, Q1 + Q2)\n",
        "...             next_state, reward, is_done, info = env.step(action)\n",
        "...             if (torch.rand(1).item() < 0.5):\n",
        "...                 best_next_action = torch.argmax(Q1[next_state])\n",
        "...                 td_delta = reward + gamma * Q2[next_state][best_next_action]  - Q1[state][action]\n",
        "...                 Q1[state][action] += alpha * td_delta\n",
        "...             else:\n",
        "...                 best_next_action = torch.argmax(Q2[next_state])\n",
        "...                 td_delta = reward + gamma * Q1[next_state][best_next_action] - Q2[state][action]\n",
        "...                 Q2[state][action] += alpha * td_delta\n",
        "...             length_episode[episode] += 1\n",
        "...             total_reward_episode[episode] += reward\n",
        "# ...             frames.append({'frame': env.render(mode='ansi'),'state': state,'action': action,'reward': reward})\n",
        "...             if is_done:\n",
        "...                 break\n",
        "...             state = next_state\n",
        "# ...     env.close()\n",
        "...     policy = {}\n",
        "...     Q = Q1 + Q2\n",
        "\n",
        "\n",
        "...     for state in range(n_state):\n",
        "...         policy[state] = torch.argmax(Q[state]).item()\n",
        "...     return Q, policy#,frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDirCtF8SwUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ">>> def gen_epsilon_greedy_policy(n_action, epsilon):\n",
        "        def policy_function(state, Q):\n",
        "            probs = torch.ones(n_action) * epsilon / n_action\n",
        "            best_action = torch.argmax(Q[state]).item()\n",
        "            probs[best_action] += 1.0 - epsilon\n",
        "            action = torch.multinomial(probs, 1).item()\n",
        "            return action\n",
        "        return policy_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMy0klpCPan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQfSMeJh399d",
        "colab_type": "text"
      },
      "source": [
        "Gamma = 1, Alpha = 0.4, Epsilon = 0.1\n",
        "\n",
        "\n",
        "141\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVvwFHENJft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ">>> n_episode = 2000\n",
        ">>> length_episode = [0] * n_episode\n",
        ">>> total_reward_episode = [0] * n_episode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXvqDJ8eFSXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha_options = [0.4, 0.5, 0.6]\n",
        "epsilon_options = [0.3, 0.1, 0.01]\n",
        "gamma = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LasQkAkKFSbN",
        "colab_type": "code",
        "outputId": "a41faa03-257f-4376-b886-84cc0987bc1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "for alpha in alpha_options:\n",
        "     for epsilon in epsilon_options:\n",
        "         length_episode = [0] * n_episode\n",
        "         total_reward_episode = [0] * n_episode\n",
        "         epsilon_greedy_policy = gen_epsilon_greedy_policy(env.action_space.n, epsilon)\n",
        "         double_q_learning(env, gamma, n_episode, alpha)\n",
        "         reward_per_step = [reward/float(step) for \n",
        "                            reward, step in zip(\n",
        "                        total_reward_episode, length_episode)]\n",
        "         print('alpha: {}, epsilon: {}'.format(alpha, epsilon))\n",
        "         print('Average reward over {} episodes: {}'.format(\n",
        "            n_episode, sum(total_reward_episode) / n_episode))\n",
        "         print('Average length over {} episodes: {}'.format(\n",
        "            n_episode, sum(length_episode) / n_episode))\n",
        "         print('Average reward per step over {} episodes: {}\\n'.format(\n",
        "            n_episode, sum(reward_per_step) / n_episode))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 0.4, epsilon: 0.3\n",
            "Average reward over 2000 episodes: -3644.3325\n",
            "Average length over 2000 episodes: 1596.939\n",
            "Average reward per step over 2000 episodes: -2.1561892832753258\n",
            "\n",
            "alpha: 0.4, epsilon: 0.1\n",
            "Average reward over 2000 episodes: -3268.065\n",
            "Average length over 2000 episodes: 1487.31\n",
            "Average reward per step over 2000 episodes: -2.058981527068195\n",
            "\n",
            "alpha: 0.4, epsilon: 0.01\n",
            "Average reward over 2000 episodes: -3157.6005\n",
            "Average length over 2000 episodes: 1450.2045\n",
            "Average reward per step over 2000 episodes: -2.023086241049618\n",
            "\n",
            "alpha: 0.5, epsilon: 0.3\n",
            "Average reward over 2000 episodes: -3335.5225\n",
            "Average length over 2000 episodes: 1401.8845\n",
            "Average reward per step over 2000 episodes: -2.2272988285111603\n",
            "\n",
            "alpha: 0.5, epsilon: 0.1\n",
            "Average reward over 2000 episodes: -3081.2705\n",
            "Average length over 2000 episodes: 1346.627\n",
            "Average reward per step over 2000 episodes: -2.102831994340026\n",
            "\n",
            "alpha: 0.5, epsilon: 0.01\n",
            "Average reward over 2000 episodes: -2973.443\n",
            "Average length over 2000 episodes: 1313.4455\n",
            "Average reward per step over 2000 episodes: -2.0450856631580323\n",
            "\n",
            "alpha: 0.6, epsilon: 0.3\n",
            "Average reward over 2000 episodes: -3165.209\n",
            "Average length over 2000 episodes: 1278.398\n",
            "Average reward per step over 2000 episodes: -2.2835741773235845\n",
            "\n",
            "alpha: 0.6, epsilon: 0.1\n",
            "Average reward over 2000 episodes: -2958.6025\n",
            "Average length over 2000 episodes: 1238.7055\n",
            "Average reward per step over 2000 episodes: -2.148824917092637\n",
            "\n",
            "alpha: 0.6, epsilon: 0.01\n",
            "Average reward over 2000 episodes: -3000.755\n",
            "Average length over 2000 episodes: 1268.6765\n",
            "Average reward per step over 2000 episodes: -2.1108950145225194\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoL9OgOFFSea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nki1lqfkFShX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i9diKndfSB5P",
        "colab": {}
      },
      "source": [
        "#10x10\n",
        ">>> gamma = 1\n",
        ">>> alpha = 0.6\n",
        ">>> epsilon = 0.1\n",
        ">>> epsilon_greedy_policy = gen_epsilon_greedy_policy(env.action_space.n, epsilon)\n",
        ">>> five_try = ['one','two','three','four','five']\n",
        "# >>> five_try = ['one']\n",
        ">>> for i in five_try:\n",
        ">>>   length_episode = [0] * n_episode\n",
        ">>>   total_reward_episode = [0] * n_episode\n",
        ">>>   optimal_Q, optimal_policy = double_q_learning(env, gamma, n_episode, alpha)\n",
        ">>>   vars()[\"length_episode_\"+i] = length_episode\n",
        ">>>   vars()[\"total_reward_episode_\"+i] = total_reward_episode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkKLkRi8FOty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "length_df = pd.DataFrame({'20x20_one' : length_episode_one ,\n",
        "                   '20x20_two' : length_episode_two,\n",
        "                   '20x20_three' : length_episode_three,\n",
        "                   '20x20_four' : length_episode_four,\n",
        "                   '20x20_five' : length_episode_five\n",
        "                   }\n",
        "                    )\n",
        "\n",
        "reward_df = pd.DataFrame({'20x20_one' : total_reward_episode_one ,\n",
        "                   '20x20_two' : total_reward_episode_two,\n",
        "                   '20x20_three' : total_reward_episode_three,\n",
        "                   '20x20_four' : total_reward_episode_four,\n",
        "                   '20x20_five' : total_reward_episode_five\n",
        "                   }\n",
        "                    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0k64buDFmhg",
        "colab_type": "code",
        "outputId": "d20fdafb-88b6-4cc5-8b5f-a57ffcbc009c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "length_df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>20x20_one</th>\n",
              "      <th>20x20_two</th>\n",
              "      <th>20x20_three</th>\n",
              "      <th>20x20_four</th>\n",
              "      <th>20x20_five</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21857</td>\n",
              "      <td>16733</td>\n",
              "      <td>6453</td>\n",
              "      <td>44433</td>\n",
              "      <td>32406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1709</td>\n",
              "      <td>4177</td>\n",
              "      <td>4041</td>\n",
              "      <td>29650</td>\n",
              "      <td>16971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5001</td>\n",
              "      <td>7012</td>\n",
              "      <td>16540</td>\n",
              "      <td>5771</td>\n",
              "      <td>7435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14902</td>\n",
              "      <td>3589</td>\n",
              "      <td>14529</td>\n",
              "      <td>2782</td>\n",
              "      <td>12587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36914</td>\n",
              "      <td>25181</td>\n",
              "      <td>13599</td>\n",
              "      <td>6152</td>\n",
              "      <td>10015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>134</td>\n",
              "      <td>237</td>\n",
              "      <td>150</td>\n",
              "      <td>256</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>171</td>\n",
              "      <td>127</td>\n",
              "      <td>232</td>\n",
              "      <td>52</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>124</td>\n",
              "      <td>457</td>\n",
              "      <td>51</td>\n",
              "      <td>126</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>161</td>\n",
              "      <td>245</td>\n",
              "      <td>157</td>\n",
              "      <td>647</td>\n",
              "      <td>432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>201</td>\n",
              "      <td>83</td>\n",
              "      <td>43</td>\n",
              "      <td>86</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      20x20_one  20x20_two  20x20_three  20x20_four  20x20_five\n",
              "0         21857      16733         6453       44433       32406\n",
              "1          1709       4177         4041       29650       16971\n",
              "2          5001       7012        16540        5771        7435\n",
              "3         14902       3589        14529        2782       12587\n",
              "4         36914      25181        13599        6152       10015\n",
              "...         ...        ...          ...         ...         ...\n",
              "1995        134        237          150         256          62\n",
              "1996        171        127          232          52         157\n",
              "1997        124        457           51         126         306\n",
              "1998        161        245          157         647         432\n",
              "1999        201         83           43          86         221\n",
              "\n",
              "[2000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxPkxR6IziV",
        "colab_type": "code",
        "outputId": "b7981717-d5a1-44eb-ad33-779702f4e027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "reward_df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>20x20_one</th>\n",
              "      <th>20x20_two</th>\n",
              "      <th>20x20_three</th>\n",
              "      <th>20x20_four</th>\n",
              "      <th>20x20_five</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-63065</td>\n",
              "      <td>-50948</td>\n",
              "      <td>-20688</td>\n",
              "      <td>-122001</td>\n",
              "      <td>-92586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6674</td>\n",
              "      <td>-13894</td>\n",
              "      <td>-13794</td>\n",
              "      <td>-83080</td>\n",
              "      <td>-42942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-18723</td>\n",
              "      <td>-22210</td>\n",
              "      <td>-49324</td>\n",
              "      <td>-21689</td>\n",
              "      <td>-23524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-40063</td>\n",
              "      <td>-12136</td>\n",
              "      <td>-43038</td>\n",
              "      <td>-9619</td>\n",
              "      <td>-31250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-93674</td>\n",
              "      <td>-65282</td>\n",
              "      <td>-40443</td>\n",
              "      <td>-19397</td>\n",
              "      <td>-30712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>-239</td>\n",
              "      <td>-567</td>\n",
              "      <td>-282</td>\n",
              "      <td>-541</td>\n",
              "      <td>-86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>-294</td>\n",
              "      <td>-187</td>\n",
              "      <td>-535</td>\n",
              "      <td>-58</td>\n",
              "      <td>-307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>-220</td>\n",
              "      <td>-1075</td>\n",
              "      <td>-57</td>\n",
              "      <td>-213</td>\n",
              "      <td>-600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>-293</td>\n",
              "      <td>-548</td>\n",
              "      <td>-388</td>\n",
              "      <td>-1490</td>\n",
              "      <td>-1077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>-360</td>\n",
              "      <td>-89</td>\n",
              "      <td>-31</td>\n",
              "      <td>-146</td>\n",
              "      <td>-425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      20x20_one  20x20_two  20x20_three  20x20_four  20x20_five\n",
              "0        -63065     -50948       -20688     -122001      -92586\n",
              "1         -6674     -13894       -13794      -83080      -42942\n",
              "2        -18723     -22210       -49324      -21689      -23524\n",
              "3        -40063     -12136       -43038       -9619      -31250\n",
              "4        -93674     -65282       -40443      -19397      -30712\n",
              "...         ...        ...          ...         ...         ...\n",
              "1995       -239       -567         -282        -541         -86\n",
              "1996       -294       -187         -535         -58        -307\n",
              "1997       -220      -1075          -57        -213        -600\n",
              "1998       -293       -548         -388       -1490       -1077\n",
              "1999       -360        -89          -31        -146        -425\n",
              "\n",
              "[2000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9GxJWdJpSB5f",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "length_df.to_csv('20x20_length_result.csv') \n",
        "reward_df.to_csv('20x20_reward_result.csv') \n",
        "# files.download('filename.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJ--NEEFSk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNpMB2-iMN7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUXWmTwuMOHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbM6WnT9MOKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6rQ_K47MOPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmdGsIHXMOSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UsfEX-HMN_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4z4YrmoOJR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}